* Development and Deployment Environments

Two main tasks in development and deployment are building your images and
setting up your deployment.  These are both handled with the
~bin/aggie-experts~ script, in the ~aggie-experts~ repository.

The two main commands for ~bin/aggie-experts~ are then, not surprisingly,
~build~ and ~setup~.  How these commands are explicitly carried out depends a
great deal on the ~--env=[dev|clean|sandbox|stage|prod]~ parameter used when
invoking this call.

Before we discussing the build and setup, let's first talk about tagging, a
very important part of the development process.

** Aggie Expert Tags
Aggie Experts tags always based on the following git command ~tag=$(git describe
--always --dirty)~.  See the git docs for more information, but with the
exception of ~dev~ env, tags *always* refer to a specific commit, and the commit
itself is *always* labeled in terms of it's distance from it's closest annotated
git tag.  Stage and production environments can only be run when the repository
is at a specific annotated tag.

The important caveat to this is that when you use ~--env=dev~, the tag is always
simply renamed as ~dirty~.  This simplifies the development steps, as the tag is
never changing, saving from creating too many different images, and also
limiting the number of times you need to ~setup~ your deployment. ~--env=dev~ is
the only setting that ever allows ~dirty~ to be part of a tag.

*** Branches
As a quick aside, aggie experts uses branches to manage our development and
updates, primarily into the default ~dev~.  Branches are *never* used in
aggie-experts to designate a particular build or deployment.  Branches will be
discussed more in the development

** Setting up your Development Environment

If you are planning to submit pull requests to Aggie Experts, then you must
setup your environment properly.


*** Prerequisites
Developers use the ~bin/aggie-experts~ script to build and setup their
processing environment.  This is a bash script, so your environment needs a
recent version of ~bash~.  In addition, the script uses ~jq~ and ~yq~.  Finally,
we use the standard POSIX ~getops~ command.  If that is not your systems
default, you can specify a pointer to the POSIX version with the
~FLAGS_GETOPT_CMD~ environmental variable.

In addition, ~bin/aggie-experts~ uses our standard ~cork-kube~ build method,
which means part of the setup involves setting up ~cork-kube~.  Aggie-Experts,
also like ~cork-kube~ uses gcloud configurations, our default being
~aggie-experts~.

*** Setup gcloud

We use the ~aggie-experts~ google cloud configuration. By default we switch to
that configuration while running ~bin/aggie-experts~.  To setup that
configuration run:

#+begin_src bash
  gcloud config configurations create aggie-experts --no-activate
  gcloud config set --configuration=aggie-experts project aggie-experts
  gcloud config set --configuration=aggie-experts compute/region us-west1
  gcloud config set --configuration=aggie-experts compute/zone us-west1-c
  gcloud config set --configuration=aggie-experts account ${me}@ucdavis.edu
  gcloud config configurations list
#+end_src

You should see something like:

#+begin_example
NAME                   IS_ACTIVE  ACCOUNT             PROJECT        COMPUTE_DEFAULT_ZONE  COMPUTE_DEFAULT_REGION
aggie-experts          False       qjhart@ucdavis.edu  aggie-experts  us-west1-c            us-west1
#+end_example

In addition, you may need to pull ~aggie-expert~ images from our repository.
You certainly will need to do that for cloud builds and deployments.  Setup
docker to fetch these from google.

#+begin_src bash
  gcloud auth configure-docker us-west1-docker.pkg.dev
#+end_src

*** Git

First clone the repo and let cork-kube know you are locally developing this
application. The default branch for aggie-experts it the ~dev~ branch.

#+begin_src bash
  git clone https://github.com/ucd-library/aggie-experts.git
  cd aggie-experts
  cork-kube build register-local-repo .
#+end_src

*** Your first build

Next let's ~build~ your environment.  This first part, just checks
your machine.  If it matches our cloud builds, we use those images, otherwise we
need to build everything locally.

#+begin_src bash
  if [[ "$(uname -m)" == 'x86_64' ]]; then
      ba='--use-registry=fuseki-image,fin'
  else
      ba='--depth=ALL'
  fi;
  bin/aggie-experts --env=dev --build-args="$ba" build
#+end_src

Your build summary should show for newly built, ~dirty~ images. They are marked
~dirty~ to indicate, these are the developers alone and are not necessarily
replicatable.

#+begin_example
 *** Build Summary: ***
localhost/aggie-experts/experts-api:dirty (2s)
localhost/aggie-experts/harvest:dirty (17s)
localhost/aggie-experts/base-service:dirty (6s)
localhost/aggie-experts/init:dirty (3s)
#+end_example

*** Your first local deployment

Now, let's deploy locally.  Run the setup command, to create your
~docker-compose.yaml~ file, and then start it up

#+begin_src bash
  bin/aggie-experts --env=dev setup
  docker compose up -d
#+end_src

You should be able to navigate to ~http://localhost/fin/admin~ to watch some
experts being built.  Then ~http://localhost/~ to see the site in action.  By
default we use port 80. If you are running other things on that port, you will
get an error starting your gateway.  Set the port to something you'd prefer, and
restart.

#+begin_src bash
  echo 'HOST_PORT=8080' > .env
  docker compose up -d
#+end_src

** Development

The different build environments are used to simplify the common development
path for modifications.   The normal development path is:

- Create a new branch for your update, set as draft.  It's a good idea to
  immediately create your pull request with this branch so progress can be
  followed.
- Develop on this branch `--env=dev`, sharing updates with your collaborators.
- Once you branch is ready, test your local deployment `--env=clean`, set your
  PR as ready for review.
- When you're PR is accepted.  Delete your local branch, reset your branch to
  `dev` and if other PRs have also been accepted you might verify your change
  still works with another `--env=clean` build and local deployment.

Note while you are testing, either your branch or the newest dev, you may want
to share with the whole team.  You can do that with the ~sandbox~ environment
described below.

Developers should *never* be developing on the ~dev~ branch.  They should always
be working on a branch specific to the issue(s) they are working on.  Because of
this, developers are encouraged to push as often as they'd like to github.  Not
all commits need to have great commit messages either.  However, if a developer
has made 10 local commits, it's not a terrible idea to rebase these into a
single commit before pushing.  But don't worry too much about that, and *avoid*
any rebasing that affects the pushed commits, it can be troublesome.  When we
accept a pull request, that is always done as a squash merge, so the `dev`
branch will always see one tidy log entry for your change.

** The `--env=[dev|clean|sandbox]` development environments

You can be developing in a number of different environments, specified with the
~-env=~ tag. The following table shows how that tag affects the build.

|------------+------------+-----------+--------------------------------+-----|
| env        | branch     | tag       | docker org/tag                 |     |
|------------+------------+-----------+--------------------------------+-----|
| dev        | *any*      | *dirty*   | localhost/aggie-experts:dirty  |     |
| clean      | *any*      | *clean*   | localhost/aggie-experts:*tag*  |     |
| sandbox    | *any*      | *clean*   | localhost/aggie-experts:*tag*  |     |
|------------+------------+-----------+--------------------------------+-----|

*** dev
Developers typically develop with `--env=dev`.  In this case, all aggie-expert
images are built locally on their machines, and they have the freedom to bind
mount various directories over containers for quicker testing.  Every build will
continuously overwrite the ~localhost/aggie-experts/??:dirty~ images, so they are
not filling their image cache with extraneous image names.  Also, you don't need
to rerun the ~setup~ command.

When you are developing in the ~dev~ environment, there are a number of additional
arguments you might be interested in:

**** `--mount=[[api,init,models,spa]]`

The four areas you are most likely to be developing is the common ~api~, the
fcrepo ~init~ files, the server-side ~models~, and the client single-page-app
~spa~.  Depending on which you are using, you can configure bind mounts to be
set for each area --or more; if you specify multiple mounts,
comma-separated. This affects that `setup` script, and you can see these bind
mounts in your ~docker-compose.yaml~ file.

**** `--build-args=*`

The ~build-args~ are additional arguments sent directly to the ~cork-kube build~
command.  The discussion above shows the most common arguments. However, in some
cases this might be different.  For example, if you are simultaneously working
on fuseki or fin. You might want to use local builds of those as you are
working.

**** `--dry-run`

If you add this, you can see the exact ~build~ command sent to ~cork-kube~.
This can be helpful for debugging why your build isn't working.


So a typical use case, might be a front end developer sets up their environment
with:

#+begin_src bash
  bin/aggie-experts --env=dev --build-args='--use-registry=fuseki-image,fin' --mount=spa build  setup
  docker compose up -d
#+end_src

Once the setup is in place, they can develop and test their system. Since their
changes are being mounted on the containers, rather than creating new
containers, they can test their changes by restarting the affected containers,
eg.

#+begin_src bash
  docker compose restart gateway spa
#+end_src

Once they are satisfied, they finalize their changes, and request a PR review
with the clean environment.

*** clean
In the clean stage, developers build their image on a clean git repository, and
build/deploy a specific tagged image to application.  Bind mounts are *never*
allowed on ~clean~ deploy.  This means that developers typically need to setup
their environment, for ~clean~ testing.

Every pull request should be tested in the ~clean~ environment before being moved
from draft for review.

If you are using an ~x86_64~ machine, then absolutely use the artifact registry
versions of your required images. This is much closer to the deployment build
later.

#+begin_src bash
  aggie-experts --env=clean --build-args='--use-registry=fuseki-image,fin' build setup
  dc down; dc up -d
#+end_src

Otherwise, try and make sure that you local build doesn't include changes in
intermediate images that you haven't committed.

#+begin_src bash
  aggie-experts --env=clean --build-args='--depth=1' build setup
  dc down; dc up -d
#+end_src

**** `--unstaged-okay`
Note, that it is possible to create an image that can't be replicated, for
example you might include a file in your builds that you never bother to commit.
Because of this the ~aggie-experts~ script will complain if you have unstaged
files. This should encourage you to keep your repository tidy, but you can skip
that error with the ~--unstaged-ok~ flag to ~aggie-experts~.

#+begin_src bash
  aggie-experts --unstaged-ok --env=clean build setup
#+end_src

*** sandbox

The sandbox env allows any clean commit to be built and deployed on
sandbox.experts.library.ucdavis.edu.  The images are built locally on sandbox,
both to test the build and to prevent images that are not expected to be
deployed to be added to the aggie-experts container repository.

Multiple developers are encouraged to have their own development/test versions
on sandbox, and you should feel relatively safe in turning off someone else's
sandbox version while you bring up your own for testing.  The different versions
are all stored in `file://sandbox.experts.library.ucdavis.edu/etc/aggie-experts`

The normal way this is done, is to prefix your test with your id, and keep
increasing the number for different tests, for example.

#+begin_src bash
  t='q022'
  my_branch='test_this'
  cd /etc/aggie-experts/
  git clone --branch=${my_branch} https://github.com/ucd-library/aggie-experts.git $t
  bin/aggie-experts --env=sandbox --build-args='--use-registry=fuseki-image,fin' build setup
  dc down
  dc up -d
#+end_src

By default, the sandbox environment uses the `fcrepo-sandbox` repository, which
takes awhile to setup on your first test.  You can monitor at
`https://sandbox.experts.library.ucdavis.edu/fin/admin`

*** Important .env entries

The `setup` command is designed to create the best default without the need for
any special environment variables. However, there reasons that you might want to
override some of these in your testing.  You can look at your
~docker-compose.yaml~ file for a complete list of ~/.env~ variables that can
affect your development.  Here are some most commonly used variables

- HOST_PORT: As discussed, may be necessary for some local deployments.
- GCS_BUCKET: Most development is hydrated with data from the ~fcrepo-dev~
  bucket, but you may instead want to test with the larger ~fcrepo-sandbox~
  bucket, or you might even want to create some new bucket to use.
- FUSEKI_PORT: Sometimes testing only the harvesting, you find you want local
  access to the fuseki container.  This will create a standard port, rather than
  selecting an ephemeral one.
- CDL_PROPAGATE_CHANGES: Under most circumstances you don't want to propogate
  your expert edits to the production system (via updates to the CDL Elements
  setup), however if you are testing that, then you would set this to true.

** The `--env=[gcb|stage|prod]` deployment environments

Developers in charge of deploying a new version use the following environments.

|-------+--------+-----------+-----------------------------------------------|
| env   | branch | tag       | dns                                           |
|-------+--------+-----------+-----------------------------------------------|
| gcb   | *dev*  | *version* | N/A                                           |
| stage | *tag*  | *version* | stage.experts.library.ucdavis.edu (blue/gold) |
| prod  | *tag*  | *version* | experts.ucdavis.edu (blue/gold)               |
|-------+--------+-----------+-----------------------------------------------|

*** gcb

You use the ~gcb~ environment to build and push new docker image to
aggie-experts artifact registry in preparation of using them on a new ~stage~ or
~prod~ environment.  The builds take place in the cloud, and this command can be
run on any computer.  However, the build only works if your are using a clean
revision tag, *and* the cork-build-repository is configured to build this
in the cloud.  Right now `fin` and `fuseki` pre-built images are required.  If
we are building version ~4.0.7~, eg.  Then that needs specification in the
`build` section of the [[https://github.com/ucd-library/cork-build-registry/blob/main/repositories/aggie-experts.json][aggie-experts.json]] config file.

A typical test and build would be:

#+begin_src bash
  cd ~/aggie-experts
  git fetch --prune --tags
  revision=4.0.7
  git checkout ${revision}
  # check it's buildable
  b=$(curl https://raw.githubusercontent.com/ucd-library/cork-build-registry/refs/heads/main/repositories/aggie-experts.json | jq --arg rev $revision '.builds[$rev]')
  if [[ "$b" != "null" ]]; then
      bin/aggie-experts --env=gcb build
  else
      echo "Not buildable"
  fi
#+end_src

~aggie-experts~ will complain if the checked out commit does not correspond to
an annotated tag.  All images will be stored in the artifact registry at
us-west1-docker.pkg.dev/aggie-experts/docker/*image_name*:*revision*


*** stage
The ~stage~ environment is only run on ~(blue|gold).experts.library.ucdavis.edu~
and only uses images that are pulled from the registry.  The best practice on
these machines is to name your next deployment like `${MAJOR}-${num}`

If you are updating an existing dataset instance:
#+begin_src bash
  num=[existing_number]
  tag=[version to run]
  cd /etc/aggie-experts/v${num}
  git checkout tag
  bin/aggie-experts --env=stage setup
  dc down
  dc up -d
#+end_src

If you are creating a new dataset environment, then

#+begin_src bash
  num=[next_number]
  tag=[version to run]
  cd /etc/aggie-experts/
  git clone --branch=$tag v${num}
  cd v${num}
  ../bin/aggie-experts --env=stage setup
  dc up -d
  # Now populate your instance
#+end_src

*** production

** Initialization Buckets

When any system starts up, it will initialize using a given GCS bucket.  Much of
the development can depend on the data within the these buckets, for in every
development phase, developers are encouraged to create their own buckets, and
alter those components.  Buckets should have the ~fcrepo-~ prefix, and be tagged
as ~fcrepo~ as well.

|------------+-------+-----------------|
| stage      | alter | gcs bucket      |
|------------+-------+-----------------|
| dev        | Y     | fcrepo-dev      |
| clean      | Y     | fcrepo-dev      |
| sandbox    | Y     | fcrepo-sandbox  |
| stage/prod | N     | fcrepo-${MAJOR} |
|------------+-------+-----------------|

** Authorization

Except under extraordinary circumstances, developers will always use the
authorization server at sandbox.auth.library.ucdavis.edu, and test and
production instances will use auth.library.ucdavis.edu.  It's important to
understand that the client is different between dev/clean and sandbox.  This is
why they require different secrets in their setup.

|---------+-------------+----------------------------------|
| stage   | auth-client | auth-server                      |
|---------+-------------+----------------------------------|
| dev     | local-dev   | auth.library.ucdavis.edu         |
| clean   | local-dev   | auth.library.ucdavis.edu         |
| sandbox | sandbox     | auth.library.ucdavis.edu         |
| test    | experts     | auth.library.ucdavis.edu         |
| prod    | experts     | auth.library.ucdavis.edu         |
|---------+-------------+----------------------------------|

* Production Deployment

The production deployment depends on multiple VMs and docker constellations,
controlled with docker-compose files.  An [[https://docs.google.com/drawings/d/1fLANXV295-rPT_NLGNDRyE1cVLNi30JMLDXwReywRjU/edit?usp=sharing][Overview Document]] gives a general
description of the deployment setup.  All traffic to the website is directed to
an apache instance that acts as a routing service to the underlying backend
service.  The router does some coarse scale redirection; maintains the SSL
certificates, but mostly monitors which of two potential backend services are
currently operational. It does this by monitoring specific ports from two VMs
gold and blue. Note blue and gold are only available within the libraries staff
VPN.  The router (router.experts.library.ucdavis.edu) will dynamically switch
between the backends based on which is currently operational.  If both are
operational, it will switch between them, if neither, it will throw a 400 error.
For Aggie Experts only one backend should be operational at any one time, but
the router doesn't care about that.

|------------------------------------+-------------------|
| machine                            | specs             |
|------------------------------------+-------------------|
| blue.experts.library.ucdavis.edu   | 32Gb, 2.5Tb, 8cpu |
| gold.experts.library.experts.edu   | 32Gb, 2.5Tb, 8cpu |
| router.experts.library.ucdavis.edu | 4Gb, 25Gb, 8cpu   |
|------------------------------------+-------------------|

On a typical redeployment of the system, you should never need to worry about
the router configuration. However, you are often very interested in what backend
server is operational.

The router manages this by including a routing indicator in the clients cookies.
The example below shows that the ROUTEID is set to `experts.blue`.

#+begin_src bash
curl -I https://experts.ucdavis.edu
#+end_src

#+begin_example
HTTP/1.1 200 OK
Date: Thu, 23 May 2024 22:47:05 GMT
Server: Apache/2.4.53 (Red Hat Enterprise Linux) OpenSSL/3.0.7
x-powered-by: Express
accept-ranges: bytes
cache-control: public, max-age=0
last-modified: Fri, 26 Apr 2024 22:28:56 GMT
etag: W/"1d2a-18f1c86a040"
content-type: text/html; charset=UTF-8
content-length: 7466
Set-Cookie: ROUTEID=experts.blue; path=/
#+end_example

The router will try and maintain the same connection with the backend if
possible, but if not it will reset this cookie, and switch to whatever backend
is working.

In our setup, there should never be two instances working, except for the few
minutes where a redeployment is in progress.  The general setup is relatively
straightforward.  The only major consideration, is that while you are preparing
your system, you need to make sure that you are *not* using the production
deployment port, otherwise the router will include your setup prematurely.

Here are the steps to deploy to blue and gold. Each new deployment should target
the non-running instance, alternating between blue and gold.

** Deployment Steps

*** Identify server
  Since we switch between blue and gold servers, you are never really sure which
  is in production, so you have to check the ROUTEID cookie with ~curl -I
  https://experts.ucdavis.edu~.

  Fill in the following instructions with this value:

  #+begin_src bash
  cur=gold # or blue
  case $cur in "gold") new="blue";; "blue") new="gold";; *) new="BAD"; esac
  version=1.0.0 # or whatever
  dir=1.0-1 # Major.Minor-ServerInstance

  alias dc=docker-compose # or 'docker compose'
  #+end_src


*** Initialize new service

  First, initialize your new service.  This example shows where you are simply
  updating the production images, but the steps are required for any changes.
  These commands simply drop any previous data, and get the latest required
  versions.

  #+begin_src bash
    ssh ${new}.experts.library.ucdavis.edu
    cd /etc/aggie-experts
    git clone https://github.com/ucd-library/aggie-experts.git ${major}.${minor}-1
    cd ${major}-${minor}-1
    git checkout ${version}
    bin/aggie-experts --env=prod|stage setup
    dc pull
  #+end_src

  If you run into an error when pulling the images, one of the following might
  be your issue:
  - docker is not authorized to pull images: `gcloud auth configure-docker`
  - you are not logged into gcloud: `gcloud auth login`
  - you have the wrong project set: `gcloud config set project aggie-experts`

  #+begin_src bash
  dc up -d
  #+end_src

  You can follow along and monitor the logs to see that the initialization script
  worked properly.

*** Retire current service

  At this point, you can vist the production pages, and verify that both backends
  are running.  This is okay, since you cannot write to the current server.  Once
  you have convinced yourself that things look good, you can stop (but don't bring
  down) the cur (now old) server.  You stop it, so if there is a big problem, you
  can

  #+begin_src bash
  ssh ${cur}.library.ucdavis.edu
  cd /etc/aggie-experts/${old}
  dc stop
  #+end_src
